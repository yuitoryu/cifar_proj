{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T01:25:31.463451Z",
     "start_time": "2025-03-12T01:25:29.029876Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "import pickle\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "# from model.res3net import Res3Net, BasicBlock\n",
    "# from model.res3netpre import Res3NetPre, BasicBlockPre\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:23:40.182089800Z",
     "start_time": "2025-03-11T02:50:54.560327Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def make_data_label(lst_of_dic, do_label=True):\n",
    "    data = torch.empty((0, 3, 32, 32))\n",
    "    if do_label:\n",
    "        label = torch.empty(0, dtype=torch.long)\n",
    "    for dic in lst_of_dic:\n",
    "        # Convert the data to a tensor and reshape\n",
    "        cur_data = torch.tensor(dic[b'data']).reshape(10000, 3, 32, 32)\n",
    "        data = torch.cat((data, cur_data), dim=0)\n",
    "        if do_label:\n",
    "            cur_label = torch.tensor(dic[b'labels'], dtype=torch.long).reshape(10000)\n",
    "            label = torch.cat((label, cur_label), dim=0)\n",
    "    # print(data[1])\n",
    "    if do_label:\n",
    "        return data, label\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "class cifar_dataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (Tensor): The raw image data with shape (n, 3, 32, 32) and pixel values in [0, 255].\n",
    "            label (Tensor): The corresponding labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        # Convert data to float and normalize pixel values to [0, 1]\n",
    "        self.transform = transforms.Compose([transforms.Normalize(mean = [0.4914, 0.4822, 0.4465], std = [0.2470, 0.2435, 0.2616])])\n",
    "        self.data = data / 255\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, lbl = self.data[index], self.label[index]\n",
    "        return img, lbl\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:23:56.136215Z",
     "start_time": "2025-03-11T15:23:55.889631Z"
    }
   },
   "source": [
    "root = r'deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\data_batch_'\n",
    "lst = []\n",
    "for i in range(5):\n",
    "    lst.append(unpickle(root+str(i+1)))\n",
    "#lst"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unpickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m lst = []\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m5\u001B[39m):\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     lst.append(\u001B[43munpickle\u001B[49m(root+\u001B[38;5;28mstr\u001B[39m(i+\u001B[32m1\u001B[39m)))\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m#lst\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'unpickle' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:23:56.156117200Z",
     "start_time": "2025-03-11T02:50:56.711379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "from PIL import Image\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# auto. choose CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Function to load CIFAR-10 dataset\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Specify the directory containing CIFAR-10 batches\n",
    "cifar10_dir = 'deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n",
    "\n",
    "# Load metadata (labels)\n",
    "meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\n",
    "label_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n",
    "\n",
    "# Load training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']\n",
    "\n",
    "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "# Convert to TensorDataset and apply transformations\n",
    "class CustomCIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform):\n",
    "        self.images = images\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)  # 保持为numpy数组\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img = Image.fromarray(self.images[idx])  # 直接转PIL图像（更高效）\n",
    "        img = self.transform(self.images[idx])  # 应用transform\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "train_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "\n",
    "# Split into training and validation sets\n",
    "#train_size = int(0.9 * len(train_dataset))\n",
    "#val_size = len(train_dataset) - train_size\n",
    "#train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),  # Convert numpy array to PIL Image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "batch_test_dict = load_cifar_batch(os.path.join(cifar10_dir, 'test_batch'))\n",
    "val_images = batch_test_dict[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "val_labels = np.array(batch_test_dict[b'labels'])\n",
    "\n",
    "val_dataset = CustomCIFAR10Dataset(val_images, val_labels, transform=test_transform)\n",
    "\n",
    "# DataLoaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True, persistent_workers=True)\n",
    "# valid_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Load test dataset\n",
    "cifar_test_path = 'deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "test_batch = load_cifar_batch(cifar_test_path)\n",
    "test_images = test_batch[b'data'].astype(np.float32) / 255.0\n",
    "\n",
    "# Convert test dataset to Tensor\n",
    "test_dataset = [(test_transform(img),) for img in test_images]\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "#train_dataset[0][0] == transform(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T15:23:56.157572600Z",
     "start_time": "2025-03-11T02:30:38.824993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T07:46:33.138705Z",
     "start_time": "2025-03-12T07:46:32.899377Z"
    }
   },
   "source": [
    "import math\n",
    "from model.resnet32 import ResNet32, BasicBlock\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        DROPOUT = 0.1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes),\n",
    "                nn.Dropout(DROPOUT)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.dropout(self.bn1(self.conv1(x))))\n",
    "        out = F.relu(self.dropout(self.bn2(self.conv2(out))))\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks=[2, 2, 1, 1], num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear1 = nn.Linear(512*block.expansion, 10)\n",
    "        # self.linear2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear1(out)\n",
    "        # out = F.relu(out)\n",
    "        # out = self.linear2(out)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Importing Model and printing Summary\n",
    "model = ResNet32(num_classes=10).to(device)\n",
    "summary(model, input_size=(3,32,32))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "        BasicBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
      "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "           Conv2d-20           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-22           [-1, 16, 32, 32]               0\n",
      "           Conv2d-23           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-24           [-1, 16, 32, 32]              32\n",
      "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-27           [-1, 16, 32, 32]               0\n",
      "           Conv2d-28           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-29           [-1, 32, 16, 16]              64\n",
      "           Conv2d-30           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-31           [-1, 32, 16, 16]              64\n",
      "           Conv2d-32           [-1, 32, 16, 16]             512\n",
      "      BatchNorm2d-33           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-34           [-1, 32, 16, 16]               0\n",
      "           Conv2d-35           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-36           [-1, 32, 16, 16]              64\n",
      "           Conv2d-37           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-38           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-39           [-1, 32, 16, 16]               0\n",
      "           Conv2d-40           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-41           [-1, 32, 16, 16]              64\n",
      "           Conv2d-42           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-44           [-1, 32, 16, 16]               0\n",
      "           Conv2d-45           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-46           [-1, 32, 16, 16]              64\n",
      "           Conv2d-47           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-48           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-49           [-1, 32, 16, 16]               0\n",
      "           Conv2d-50           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-51           [-1, 32, 16, 16]              64\n",
      "           Conv2d-52           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-56             [-1, 64, 8, 8]             128\n",
      "           Conv2d-57             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-58             [-1, 64, 8, 8]             128\n",
      "           Conv2d-59             [-1, 64, 8, 8]           2,048\n",
      "      BatchNorm2d-60             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-61             [-1, 64, 8, 8]               0\n",
      "           Conv2d-62             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-63             [-1, 64, 8, 8]             128\n",
      "           Conv2d-64             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-65             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-66             [-1, 64, 8, 8]               0\n",
      "           Conv2d-67             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-68             [-1, 64, 8, 8]             128\n",
      "           Conv2d-69             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-70             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-71             [-1, 64, 8, 8]               0\n",
      "           Conv2d-72             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-73             [-1, 64, 8, 8]             128\n",
      "           Conv2d-74             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-75             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-76             [-1, 64, 8, 8]               0\n",
      "           Conv2d-77             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-78             [-1, 64, 8, 8]             128\n",
      "           Conv2d-79             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-81             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-82             [-1, 64, 1, 1]               0\n",
      "           Linear-83                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 466,906\n",
      "Trainable params: 466,906\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.91\n",
      "Params size (MB): 1.78\n",
      "Estimated Total Size (MB): 7.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:51:05.566956Z",
     "start_time": "2025-03-11T02:51:05.551033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4823, -2.5297, -2.1597, -2.2404, -2.4353, -2.2294, -2.1318, -2.1364,\n",
       "         -2.3743, -2.4075]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_dataset[0][0].to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T05:27:54.867423Z",
     "start_time": "2025-03-11T05:27:54.657964Z"
    }
   },
   "source": [
    "# Function to load CIFAR-10 batch files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Load one batch\n",
    "batch = unpickle(r'deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl')\n",
    "# batch = unpickle(r'deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1')\n",
    "images = test_images\n",
    "# labels = batch[b'labels']\n",
    "\n",
    "# Reshape images\n",
    "# images = images.reshape(-1, 3, 32, 32)\n",
    "print(images.shape)\n",
    "#images  = images.transpose(0, 2, 3, 1)\n",
    "# images = images[:,:,:,torch.tensor([0,1,2])]\n",
    "# CIFAR-10 class labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Plot some images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(images[i+110])\n",
    "    # ax.set_title(class_names[labels[i]])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mdict\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# Load one batch\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m batch = \u001B[43munpickle\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdeep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# batch = unpickle(r'deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1')\u001B[39;00m\n\u001B[32m     10\u001B[39m images = test_images\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36munpickle\u001B[39m\u001B[34m(file)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34munpickle\u001B[39m(file):\n\u001B[32m      3\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file, \u001B[33m'\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fo:\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m         \u001B[38;5;28mdict\u001B[39m = \u001B[43mpickle\u001B[49m.load(fo, encoding=\u001B[33m'\u001B[39m\u001B[33mbytes\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mdict\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name 'pickle' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T05:50:11.642159Z",
     "start_time": "2025-03-11T05:50:11.630106Z"
    }
   },
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:30:44.678504Z",
     "start_time": "2025-03-11T02:30:44.671112Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "def model_testing(model, device, test_dataloader, test_acc, test_losses, misclassified = []):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    # label = 0\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for index, (data, target) in enumerate(test_dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            for d,i,j in zip(data, pred, target):\n",
    "                if i != j:\n",
    "                    misclassified.append([d.cpu(),i[0].cpu(),j.cpu()])\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))\n",
    "\n",
    "    test_acc.append(100. * correct / len(test_dataloader.dataset))\n",
    "    return misclassified\n",
    "\n",
    "# def model_training(model, device, train_dataloader, optimizer, train_acc, train_losses, criterion):\n",
    "#\n",
    "#     model.train()\n",
    "#     # pbar = tqdm(train_dataloader)\n",
    "#     correct = 0\n",
    "#     processed = 0\n",
    "#     running_loss = 0.0\n",
    "#\n",
    "#     for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         with autocast(enabled=True):\n",
    "#             y_pred = model(data)\n",
    "#             loss = F.nll_loss(y_pred, target)\n",
    "#\n",
    "#\n",
    "#         train_losses.append(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#         pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         processed += len(data)\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         # pbar.set_description(desc=f'Loss={loss.item():.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "#         train_acc.append(100*correct/processed)\n",
    "#     print(f'Loss={loss.item():.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "def model_training(model, device, train_dataloader, optimizer, train_acc, train_losses, criterion):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    scaler = GradScaler(enabled=True)  # 确保启用Scaler\n",
    "    running_loss = 0.0\n",
    "    PBAR = tqdm(train_dataloader)\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(PBAR):\n",
    "        # print(batch_idx)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            y_pred = model(data)\n",
    "            loss = criterion(y_pred, target)  # 使用CrossEntropyLoss而非NLLLoss\n",
    "\n",
    "        scaler.scale(loss).backward()  # 使用scaler缩放梯度\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        processed += len(data)\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # pbar.set_description(desc=f'Loss={loss.item():.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "        train_acc.append(100*correct/processed)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        break\n",
    "    print(f'Loss={loss.item():.4f} lr={lr} Accuracy={100*correct/processed:0.2f}')\n",
    "    \n",
    "def lr_warmup(current_epoch):\n",
    "    if current_epoch < 5:  # 前5轮预热\n",
    "        return (0.01 + (0.1 - 0.01) * (current_epoch / 5))\n",
    "    else:\n",
    "        return 1.0  # 后续由余弦退火接管"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-11T02:52:08.884918Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seer2\\AppData\\Local\\Temp\\ipykernel_14348\\3423303052.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=True)  # 确保启用Scaler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/391 [00:00<?, ?it/s]C:\\Users\\seer2\\AppData\\Local\\Temp\\ipykernel_14348\\3423303052.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.3060 lr=0.04000000000000001 Accuracy=40.65\n",
      "\n",
      "Test set: Average loss: 1.5500, Accuracy: 4751/10000 (47.51%)\n",
      "\n",
      "EPOCHS : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:19<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9255 lr=0.001 Accuracy=60.04\n",
      "\n",
      "Test set: Average loss: 1.0374, Accuracy: 6225/10000 (62.25%)\n",
      "\n",
      "EPOCHS : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8412 lr=0.0028000000000000004 Accuracy=63.91\n",
      "\n",
      "Test set: Average loss: 0.9588, Accuracy: 6564/10000 (65.64%)\n",
      "\n",
      "EPOCHS : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8177 lr=0.004600000000000001 Accuracy=66.52\n",
      "\n",
      "Test set: Average loss: 0.9067, Accuracy: 6801/10000 (68.01%)\n",
      "\n",
      "EPOCHS : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7065 lr=0.0064 Accuracy=69.46\n",
      "\n",
      "Test set: Average loss: 0.8349, Accuracy: 7153/10000 (71.53%)\n",
      "\n",
      "EPOCHS : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:21<00:00, 18.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.7024 lr=0.0082 Accuracy=72.22\n",
      "\n",
      "Test set: Average loss: 0.8372, Accuracy: 7148/10000 (71.48%)\n",
      "\n",
      "EPOCHS : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:19<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.7420 lr=0.19978136272187746 Accuracy=30.81\n",
      "\n",
      "Test set: Average loss: 2.8126, Accuracy: 3273/10000 (32.73%)\n",
      "\n",
      "EPOCHS : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:19<00:00, 19.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=1.2751 lr=0.19912640693269754 Accuracy=50.09\n",
      "\n",
      "Test set: Average loss: 1.3664, Accuracy: 5274/10000 (52.74%)\n",
      "\n",
      "EPOCHS : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:19<00:00, 19.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9909 lr=0.19803799658748095 Accuracy=61.14\n",
      "\n",
      "Test set: Average loss: 1.0419, Accuracy: 6312/10000 (63.12%)\n",
      "\n",
      "EPOCHS : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:19<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.8278 lr=0.19652089102773487 Accuracy=67.03\n",
      "\n",
      "Test set: Average loss: 1.0087, Accuracy: 6641/10000 (66.41%)\n",
      "\n",
      "EPOCHS : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 19.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.9432 lr=0.19458172417006347 Accuracy=70.96\n",
      "\n",
      "Test set: Average loss: 0.9889, Accuracy: 6755/10000 (67.55%)\n",
      "\n",
      "EPOCHS : 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▋                                                           | 101/391 [00:05<00:15, 19.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 22\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCHS):\n\u001B[32m     21\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mEPOCHS : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m     \u001B[43mmodel_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_acc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m     scheduler.step()\n\u001B[32m     24\u001B[39m     misclassified = model_testing(model, device, valid_loader, valid_acc, valid_losses)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 73\u001B[39m, in \u001B[36mmodel_training\u001B[39m\u001B[34m(model, device, train_dataloader, optimizer, train_acc, train_losses, criterion)\u001B[39m\n\u001B[32m     70\u001B[39m running_loss = \u001B[32m0.0\u001B[39m\n\u001B[32m     71\u001B[39m PBAR = tqdm(train_dataloader)\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mPBAR\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# print(batch_idx)\u001B[39;49;00m\n\u001B[32m     75\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    707\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m708\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    709\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    710\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    711\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    712\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    713\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    714\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    762\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    763\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m764\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    765\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    766\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 64\u001B[39m, in \u001B[36mCustomCIFAR10Dataset.__getitem__\u001B[39m\u001B[34m(self, idx)\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[32m     63\u001B[39m     \u001B[38;5;66;03m# img = Image.fromarray(self.images[idx])  # 直接转PIL图像（更高效）\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     img = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 应用transform\u001B[39;00m\n\u001B[32m     65\u001B[39m     label = \u001B[38;5;28mself\u001B[39m.labels[idx]\n\u001B[32m     66\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img, label\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[39m, in \u001B[36mCompose.__call__\u001B[39m\u001B[34m(self, img)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transforms:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m         img = \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[39m, in \u001B[36mToTensor.__call__\u001B[39m\u001B[34m(self, pic)\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[32m    130\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    131\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m    132\u001B[39m \u001B[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    135\u001B[39m \u001B[33;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[32m    136\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001B[39m, in \u001B[36mto_tensor\u001B[39m\u001B[34m(pic)\u001B[39m\n\u001B[32m    174\u001B[39m img = img.permute((\u001B[32m2\u001B[39m, \u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m)).contiguous()\n\u001B[32m    175\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch.ByteTensor):\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdefault_float_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdiv\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m255\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# 定义预热函数\n",
    "warmup_epochs = 5\n",
    "lr_lambda = lambda epoch: (epoch + 1) / warmup_epochs if epoch < warmup_epochs else 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (EPOCHS - warmup_epochs)))\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "train_acc = []\n",
    "train_losses = []\n",
    "valid_acc = []\n",
    "valid_losses = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    print(f'EPOCHS : {i}')\n",
    "    model_training(model, device, train_loader, optimizer, train_acc, train_losses, criterion)\n",
    "    scheduler.step()\n",
    "    misclassified = model_testing(model, device, valid_loader, valid_acc, valid_losses)\n",
    "\n",
    "    if i < 5:\n",
    "        lr_scale = lr_warmup(i)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.1 * lr_scale\n",
    "    else:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T00:11:49.555241Z",
     "start_time": "2025-03-11T00:11:28.891451Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(test, batch_size=1, shuffle=False)\n",
    "valid_loader2 = DataLoader(valid_set, batch_size=1, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "result = []\n",
    "for img, _ in test_loader:\n",
    "    model.eval()\n",
    "    img = img.to(device)\n",
    "    y_pred = model(img)\n",
    "    pred = int(y_pred.argmax(dim=1, keepdim=True))\n",
    "    result.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T00:12:17.993181Z",
     "start_time": "2025-03-11T00:12:17.986898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0745, 0.0039, 0.0039,  ..., 0.0039, 0.0706, 0.0000],\n",
       "          [0.0000, 0.0706, 0.0000,  ..., 0.4118, 0.4039, 0.4471],\n",
       "          [0.4157, 0.4078, 0.3412,  ..., 0.4196, 0.3882, 0.3804],\n",
       "          ...,\n",
       "          [0.0039, 0.0000, 0.0549,  ..., 0.0471, 0.0078, 0.0039],\n",
       "          [0.0824, 0.0078, 0.0039,  ..., 0.5843, 0.6510, 0.6627],\n",
       "          [0.5686, 0.4588, 0.4431,  ..., 0.0235, 0.0235, 0.0549]],\n",
       " \n",
       "         [[0.0039, 0.0000, 0.0588,  ..., 0.0471, 0.0078, 0.0039],\n",
       "          [0.0745, 0.0039, 0.0000,  ..., 0.5412, 0.5961, 0.6588],\n",
       "          [0.6275, 0.6510, 0.6745,  ..., 0.0745, 0.0706, 0.0588],\n",
       "          ...,\n",
       "          [0.7020, 0.5608, 0.6549,  ..., 0.3961, 0.2902, 0.2392],\n",
       "          [0.2235, 0.1725, 0.3843,  ..., 0.0863, 0.0392, 0.0196],\n",
       "          [0.1059, 0.0745, 0.0235,  ..., 0.7137, 0.6549, 0.7294]],\n",
       " \n",
       "         [[0.7255, 0.6588, 0.7373,  ..., 0.4941, 0.3804, 0.3216],\n",
       "          [0.3020, 0.2353, 0.2235,  ..., 0.4941, 0.4824, 0.4275],\n",
       "          [0.0941, 0.0588, 0.0353,  ..., 0.6078, 0.6078, 0.6588],\n",
       "          ...,\n",
       "          [0.3647, 0.3608, 0.1804,  ..., 0.1843, 0.4039, 0.3922],\n",
       "          [0.2078, 0.3725, 0.3647,  ..., 0.2902, 0.1608, 0.1647],\n",
       "          [0.1412, 0.0588, 0.1686,  ..., 0.3765, 0.3686, 0.2235]]]),\n",
       " tensor([-1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T00:12:33.475113Z",
     "start_time": "2025-03-11T00:12:33.467228Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_output(result):\n",
    "    out = ['ID,Labels']\n",
    "    for i in range(len(result)):\n",
    "        cur = str(i) + str(',') + str(int(result[i]))\n",
    "        out.append(cur)\n",
    "    return '\\n'.join(out)\n",
    "with open(\"output.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(make_output(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
